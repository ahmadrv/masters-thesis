\chapter{مروری بر کارهای پیشین}
این بخش مفاهیم اساسی و زمینهٔ موردنیاز برای درک اصول پایه‌ای محاسبات کلاسیک و کوانتومی را پوشش می‌دهد و سعی در معرفی تاریخچه، اجزای بنیادی و تفاوت‌های کلیدی بین این دو مدل به خواننده را دارد. این توضیح باهدف جامع بودن، جزئیات تا حدی کافی را ارائه می‌دهد تا اطمینان حاصل شود که برای خوانندگانی که پیش‌زمینه‌ای در این زمینه ندارند، شفافیت داشته باشد. تمامی توضیحات این فصل برگرفته از \cite{wong_introduction_2022} می‌باشد مگر اینکه در مباحثی خاص از دیگر ارجاعات استفاده شده باشد.
\section{اطلاعات و محاسبات کلاسیک}
\subsection{تکامل تاریخی محاسبات}
مفهوم محاسبات با محاسبات دستی توسط انسان‌ها متولد شد. تمدن‌های اولیه مانند مصری‌ها و بابلی‌ها از ابزارهایی مانند چرتکه برای انجام عملیات ریاضی استفاده می‌کردند. مفهوم محاسبات خودکار در قرن هفدهم با مخترعانی مانند
\lr{Blaise Pascal}،
سازندهٔ ماشین‌حساب مکانیکی، تحول یافت. در قرن نوزدهم
\lr{Charles Babbage}،
موتور تحلیلی را طراحی کرد، یک رایانهٔ مکانیکی همه‌منظوره که هرگز تکمیل نشد.
\lr{Ada Lovelace}،
که اغلب به‌عنوان اولین برنامه‌نویس رایانه شناخته می‌شود، الگوریتم‌هایی برای این ماشین نوشت که پتانسیل آن را فراتر از محاسبه ساده، نشان می‌داد.
قرن بیستم نشانه‌ای از گذار به رایانه‌های الکترونیکی بود. مدل نظری
\lr{Alan Turing}،
ماشین تورینگ، اساس علم رایانه مدرن را بنا نهاد. در طول جنگ جهانی دوم، ماشین‌هایی مانند
\lr{Colossus}
و
\lr{ENIAC}
برای شکستن رمزها و محاسبات بالستیکی ساخته شدند. این رایانه‌های اولیه از لامپ‌های خلأ استفاده می‌کردند که بعدها در دهه ۱۹۵۰ با ترانزیستورها جایگزین شدند و به توسعه ماشین‌های کوچک‌تر و قابل‌اعتمادتر منجر شد.
اختراع مدار مجتمع در دهه ۱۹۶۰ توسط
\lr{Jack Kilby}
و
\lr{Robert Noyce}،
محاسبات را با امکان ساخت ریزپردازنده‌های فشرده و قدرتمند متحول کرد. این جهش فناوری، راه را برای رایانه‌های شخصی در دهه ۱۹۸۰ باز کرد و قدرت محاسبات را به خانه‌ها و کسب‌وکارهای کوچک آورد. امروزه، رایانه‌های کلاسیک جزء جدایی‌ناپذیر زندگی مدرن هستند، از ارتباطات و سرگرمی تا تحقیقات علمی و خودکارسازی صنعتی. حضور گسترده آن‌ها و رابط‌های کاربری آسان، امکان انجام کارهای پیچیده را بدون نیاز به درک عمیق از فناوری زیربنایی برای افراد فراهم می‌کند.

\subsection{مفاهیم بنیادی در محاسبات کلاسیک}
رایانه‌های کلاسیک بر اساس منطق دودویی عمل می‌کنند، جایی که اطلاعات با استفاده از بیت‌ها نشان داده می‌شود. یک بیت، یک رقم دودویی است که می‌تواند یکی از دو مقدار ۰ یا ۱ را داشته باشد. این بیت‌ها واحدهای اصلی اطلاعات در یک سامانهٔ دیجیتال هستند. در سامانه‌های دیجیتال مفهوم دیگری به نام گیت‌های منطقی مطرح است. گیت‌ها برای اعمال تغییرات بر روی بیت‌ها مورداستفاده قرار می‌گیرند. در ادامه به معرفی ابتدایی تعدادی از این گیت‌ها می‌پردازیم.
\paragraph{گیت :AND}
تنها زمانی که هر دو ورودی ۱ باشند، خروجی ۱ می‌دهد. این گیت عملیات پیوند منطقی را انجام می‌دهد.

\paragraph{گیت :OR}
اگر حداقل یکی از ورودی‌ها ۱ باشد، خروجی ۱ می‌دهد. این گیت عملیات جداکنندهٔ منطقی را انجام می‌دهد.

\paragraph{گیت :NOT}
مقدار ورودی را معکوس می‌کند، به طوری که اگر ورودی ۰ باشد، خروجی ۱ و بالعکس.

این گیت‌ها می‌توانند با هم ترکیب شوند تا مدارهای پیچیده‌تری ایجاد کنند که قابلیت انجام عملیات‌های ریاضی و منطقی را دارند. به عنوان مثال، یک مدار نیم‌جمع‌کننده با ترکیب یک گیت AND و یک گیت XOR دو عدد دودویی را جمع می‌کند و حاصل جمع و بیت نقلی تولید می‌کند.

\subsection{برگشت‌پذیری و جامعیت‌پذیری محاسبات}
بیشتر گیت‌های منطقی کلاسیک غیرقابل‌برگشت هستند، به این معنا که خروجی به طور یکتا ورودی را تعیین نمی‌کند. به‌عنوان‌مثال، دانستن این که خروجی یک گیت AND برابر با ۰ است، اطلاعات دقیقی درباره ورودی‌ها نمی‌دهد. بااین‌حال، برخی عملیات مانند گیت \lr{Toffoli} (که به‌عنوان گیت NOT کنترل‌شده نیز شناخته می‌شود) برگشت‌پذیر هستند. گیت \lr{Toffoli} حالت بیت خروجی را درصورتی‌که بیت‌های کنترل در حالت مشخصی باشند، معکوس می‌کند.

برگشت‌پذیری یک مفهوم کلیدی در محاسبات کوانتومی است، جایی که همهٔ عملیات باید به دلیل قوانین مکانیک کوانتومی برگشت‌پذیر باشند. این خاصیت تضمین می‌کند که اطلاعات در طول محاسبه از بین نمی‌رود و یکپارچگی حالت‌های کوانتومی حفظ می‌شود.
\subsubsection{مجموعهٔ گیت‌های جامع}
در محاسبات کلاسیک، یک مجموعهٔ گیت جامع مجموعه‌ای از گیت‌هاست که می‌توانند برای انجام هر عملیات منطقی ترکیب شوند. گیت، NAND به‌عنوان‌مثال، یک مجموعهٔ جامع است؛ زیرا هر گیت دیگری (مانند AND ، NOT و غیره) را می‌توان با استفاده از آن ساخت. این مفهوم در محاسبات کوانتومی نیز به کار می‌رود، جایی که یک مجموعهٔ گیت‌های کوانتومی جامع و عمومی مانند $\mathbf{\{CNOT, H, T\}}$ می‌تواند برای انجام هر عملیات کوانتومی استفاده شود.

\subsection{تصحیح خطا و پیچیدگی محاسباتی}
\subsubsection{تصحیح خطای کلاسیک}
خطاها در محاسبات کلاسیک ممکن است از منابع مختلفی مانند نویز الکتریکی یا خرابی‌های سخت‌افزاری ناشی شوند. فن‌های تصحیح خطا برای اطمینان از انتقال و پردازش صحیح داده‌ها، ضروری هستند. یکی از روش‌های ساده، کد تکرار است که در آن هر بیت چندین بار تکرار می‌شود (مثلاً ۰ به ۰۰۰ تبدیل می‌شود) تا بتوان خطاها را با استفاده از رأی‌گیری اکثریت، شناسایی و اصلاح کرد.

\subsubsection{تصحیح خطای کوانتومی}
حالت‌های کوانتومی به دلیل برهم‌کنش‌های محیطی و سایر پدیده‌های کوانتومی بیش‌تر مستعد خطا هستند. رمزهای تصحیح خطای کوانتومی مانند کد Shor اطلاعات کوانتومی را با رمزگذاری یک بیت کوانتومی در چند بیت فیزیکی محافظت می‌کنند و به‌این‌ترتیب می‌توانند خطاها را شناسایی و اصلاح کنند بدون اینکه حالت کوانتومی را مستقیماً اندازه‌گیری کنند.

\subsubsection{پیچیدگی محاسباتی}
نظریهٔ پیچیدگی محاسباتی، مسائل را بر اساس منابع موردنیاز برای حل آن‌ها، مانند زمان و حافظه، طبقه‌بندی می‌کند. در محاسبات کلاسیک، مسائل قابل‌حل در زمان چندجمله‌ای \lr{(P)}، ساده در نظر گرفته می‌شوند، درحالی‌که مسائل قابل‌حل توسط رایانه‌های کوانتومی در زمان چندجمله‌ای (BQP) با تفاوتی که با مسائل سادهٔ کلاسیک دارد، می‌تواند مزیت بالقوه‌ای در محاسبات کوانتومی را نشان دهد. این تفاوت‌ها دلالت‌های نظری و عملی محاسبات کوانتومی در حل مسائل را برجسته می‌کند. در ادامه، در طول قسمت‌های مختلف به این تفاوت‌ها اشاره خواهد شد.

\subsection{نقش محاسبات کلاسیک در محاسبات کوانتومی}
درک محاسبات کلاسیک برای درک مفاهیم محاسبات کوانتومی ضروری است. الگوریتم‌های کوانتومی اغلب شامل اجزای کلاسیک هستند و سامانه‌های کنترل کلاسیک، مدیریت عملیات کوانتومی را بر عهده دارند. به‌عنوان‌مثال، اجرای تصحیح خطای کوانتومی به پردازش کلاسیک نیاز دارد تا خطاها را در حالت‌های کوانتومی شناسایی و اصلاح کند. علاوه بر این، بسیاری از الگوریتم‌های کوانتومی مانند الگوریتم‌های \lr{Shor} و \lr{Grover} همتایان کلاسیک دارند که بینش‌هایی درباره همتایان کوانتومی آن‌ها ارائه می‌دهد.

\section{اطلاعات و محاسبات کوانتومی}
\subsection{معرفی اطلاعات کوانتومی}
محاسبات کوانتومی الگوی جدیدی را معرفی می‌کند که در آن اطلاعات با استفاده از بیت‌های کوانتومی یا کیوبیت‌ها نمایش داده می‌شود. برخلاف بیت‌های کلاسیک که تنها می‌توانند در یکی از دو حالت (۰ یا ۱) باشند، کیوبیت‌ها می‌توانند به طور هم‌زمان در ترکیبی از هر دو حالت وجود داشته باشند. این خاصیت از اصول مکانیک کوانتومی، به‌ویژه، برهم‌نهی خطی حالت‌های کوانتومی، ناشی می‌شود.

یک کیوبیت می‌تواند به‌صورت $|\psi\rangle = \alpha|0\rangle + \beta|1\rangle$ نمایش داده شود که در آن $\alpha$ و $\beta$ اعداد مختلط هستند و $|\alpha|^2 + |\beta|^2 = 1$. این نمایش، احتمالات اندازه‌گیری کیوبیت در حالت $|0\rangle$ یا $|1\rangle$ را توصیف می‌کند. ضریب‌های $\alpha$ و $\beta$ به‌عنوان دامنه‌های احتمال شناخته می‌شوند و مربع اندازه آن‌ها احتمال مربوطه را مشخص می‌کند.

\subsection{کیوبیت‌ها و حالت‌های کوانتومی}
اصل برهم‌نهی اجازه می‌دهد یک کیوبیت اطلاعات بیشتری نسبت به یک بیت کلاسیک حمل کند. درحالی‌که یک بیت کلاسیک فقط می‌تواند در یکی از دو حالت باشد، یک کیوبیت می‌تواند هر ترکیبی از این حالت‌ها را به‌صورت هم‌زمان نشان دهد. این قابلیت منجر به محاسبات موازی می‌شود که یک خاصیت ذاتی در محاسبات کوانتومی است.

حالت‌های کوانتومی را می‌توان بر روی 
\lr{Bloch sphere}،
یک نمایش هندسی، تجسم کرد. هر نقطه روی سطح این نمایش هندسی، نشان‌دهندهٔ یک حالت خالص کوانتومی است. حالت‌های خاص مانند $|0\rangle$ و $|1\rangle$ در قطب‌های شمال و جنوب کره قرار دارند، درحالی‌که حالات دیگر روی سطح پراکنده‌اند.

\subsection{اندازه‌گیری و اصل ناپیوستگی}
یکی از تفاوت‌های کلیدی بین محاسبات کلاسیک و کوانتومی در نحوهٔ پردازش اطلاعات کوانتومی در طول اندازه‌گیری است. برخلاف اندازه‌گیری‌های کلاسیک که اطلاعات را بدون تأثیر بر سامانه اندازه‌گیری می‌کنند، اندازه‌گیری در سامانه‌های کوانتومی می‌تواند حالت کوانتومی را تغییر دهد یا به‌اصطلاح ناهمدوس کند.

هنگامی که یک کیوبیت اندازه‌گیری می‌شود، حالت آن به یکی از دو حالت پایه‌ای $|0\rangle$ یا $|1\rangle$ به‌اصطلاح، فرومی‌ریزد. احتمال اندازه‌گیری هر حالت پایه‌ای با مربع اندازه دامنهٔ مربوطه تعیین می‌شود. این اصل ناپیوستگی به این معناست که نمی‌توانیم قبل از اندازه‌گیری پیش‌بینی قطعی از نتیجه اندازه‌گیری داشته باشیم، بلکه فقط احتمالات ممکن را می‌توانیم محاسبه کنیم.

\subsection{درهم‌تنیدگی کوانتومی}
درهم‌تنیدگی کوانتومی یکی از پدیده‌های برجسته مکانیک کوانتومی است که هنگامی رخ می‌دهد که حالت کوانتومی دو یا چند ذره به طور جدایی‌ناپذیری به هم مرتبط شود. درهم‌تنیدگی اجازه می‌دهد که اندازه‌گیری حالت یکی از ذرات بلافاصله حالت ذره دیگر را تعیین کند، حتی اگر این ذرات در فواصل دور از هم قرار داشته باشند. این پدیده «شبح‌وار بودن عمل در فاصله» را که توسط \lr{Albert Einstein} به‌عنوان «کنشی شگفت‌انگیز» توصیف شده، معرفی می‌کند.

یکی از نمونه‌های معروف درهم‌تنیدگی، \lr{Bell's theorem} است که در آن دو کیوبیت در حالتی هستند که هیچ توصیف محلی و قطعی نمی‌تواند حالت هر دو کیوبیت را به طور مستقل تعیین کند. درهم‌تنیدگی، پایه‌ای برای بسیاری از پروتکل‌های کوانتومی مانند رمزنگاری کوانتومی و انتقال آنی کوانتومی است.

در ادامه به مفهومی به نام «رتبهٔ \lr{Schmidt}» می‌پردازیم که در توضیح میزان در‌هم‌تنیدگی دو زیرسیستم به ما کمک می‌کند.

\subsubsection{تجزیه و رتبهٔ Schmidt}
رتبهٔ Schmidt مفهومی در نظریه اطلاعات کوانتومی است که به‌ویژه در زمینهٔ حالت‌های کوانتومی دوگانه اهمیت دارد. این رتبه به تعداد جملات ناصفر در تجزیهٔ Schmidt یک حالت خالص اشاره دارد که دو زیرسیستم (که اغلب به‌صورت A و B نشان داده می‌شوند) را توصیف می‌کند.

هر حالت خالص \(|\psi\rangle\) که در فضای \(H_A \otimes H_B\) (محصول تانسوری فضای سیستم‌های $A$ و $B$) تعریف شده باشد، می‌تواند به‌صورت تجزیهٔ Schmidt بیان شود:
\[
|\psi\rangle = \sum_{i=1}^{r} c_i |a_i\rangle |b_i\rangle
\]
در حالی که

\begin{itemize}
	\item[-] \(c_i\) ضرایب غیرمنفی هستند.
	\item[-] \(|a_i\rangle\) بردارهای پایهٔ متعامد برای زیرسیستم $A$ هستند.
	\item[-] \(|b_i\rangle\) بردارهای پایهٔ متعامد برای زیرسیستم $B$ هستند.
	\item[-] \(r\)، که به عنوان رتبهٔ Schmidt شناخته می‌شود، برابر است با تعداد ضرایب ناصفر (\(c_i > 0\))
\end{itemize}


با دانستن رتبهٔ Schmidt دیدگاهی درباره سطح درهم‌تنیدگی بین دو زیرسیستم بدست می‌آید. اگر \(r = 1\) باشد، حالت قابل جداسازی است؛ یعنی هیچ درهم‌تنیدگی بین آن‌ها وجود ندارد ولی اگر \(r > 1\) شود، حالت نوعی درهم‌تنیدگی را نشان می‌دهد که نشان‌گر جدایی‌ناپذیری سیستم خواهد بود؛ رتبه‌های بالاتر نشان‌دهندهٔ روابط پیچیده‌تری بین زیرفضاها هستند.

به طور خلاصه، درک رتبهٔ Schmidt به فیزیک‌دانان و پژوهش‌گران در زمینهٔ سیستم‌های کوانتومی بینشی بهتر درباره ساختار این سیستم‌ها از نظر خاصیت جدایی‌پذیری در مقابل ویژگی‌های درهم‌تنیدگی می‌دهد.

\subsection{تصحیح خطای کوانتومی}
یکی از چالش‌های اصلی در محاسبات کوانتومی مقابله با خطاهایی است که در اثر ناهمدوسی و نویز ایجاد می‌شوند. تصحیح خطای کوانتومی برای حفظ یکپارچگی اطلاعات کوانتومی ضروری است. برخلاف بیت‌های کلاسیک که می‌توانند به طور مستقل کنترل شوند، کیوبیت‌ها حساس به نویز هستند و ممکن است خطاهای پیچیده‌ای مانند تغییر بیت و یا تغییر فاز را تجربه کنند.

\subsubsection{کد \lr{Shor}}
یکی از اولین کدهای تصحیح خطای کوانتومی است که یک کیوبیت منطقی را به نُه کیوبیت فیزیکی رمزگذاری می‌کند. این کد می‌تواند خطاهای تک‌کیوبیتی دلخواه را با شناسایی و تصحیح هر دو نوع خطای تغییر بیت و تغییر فاز، اصلاح کند. کد با پخش اطلاعات کوانتومی در میان چندین کیوبیت کار می‌کند که اجازه می‌دهد خطاها بدون اندازه‌گیری مستقیم حالت، شناسایی و اصلاح شوند.
\subsubsection{اندازه‌گیری \lr{Syndrome}}
در تصحیح خطای کوانتومی، اندازه‌گیری \lr{Syndrome} برای شناسایی وجود و نوع خطاها انجام می‌شود. این اندازه‌گیری حالت کوانتومی را به یک زیرفضای مربوط به \lr{Syndrome} خطا نگاشت می‌کند، که امکان شناسایی و تصحیح خطاها را فراهم می‌کند. در اندازه‌گیری‌های \lr{Syndrome} یکپارچگی حالت کوانتومی حفظ می‌شود چرا که اطلاعات کوانتومی کدگذاری شده را مختل نمی‌کنند.

\section{تحلیل تطبیقی: محاسبات کلاسیک در مقابل کوانتومی}
محاسبات کوانتومی چندین مزیت نسبت به محاسبات کلاسیک دارد، به‌ویژه در حوزهٔ برخی از مسائل محاسباتی. درحالی‌که رایانه‌های کلاسیک به عملیات قطعی بر روی بیت‌ها متکی هستند، رایانه‌های کوانتومی از ماهیت احتمالی مکانیک کوانتومی بهره می‌برند و از کیوبیت‌ها برای تبدیل و فناوری اطلاعات استفاده می‌کنند.

\subsection{بهبود پیچیدگی در مدل کوانتومی}
الگوریتم‌های کوانتومی می‌توانند بهبود پیچیدگی نمایی در حل برخی مسائل ارائه دهند. به‌عنوان‌مثال، الگوریتم \lr{Shor} می‌تواند اعداد بزرگ را به طور نمایی، سریع‌تر از بهترین الگوریتم‌های کلاسیک فاکتور کند که می‌تواند تهدیدی برای سامانه‌های رمزنگاری کلاسیک باشد. از سوی دیگر، الگوریتم \lr{Grover} برای مسائل جستجوی بی‌ساختار، بهبود مربعی در پیچیدگی محاسباتی راه‌حل مسئله، ارائه می‌دهد.

\subsection{چالش‌های محاسبات کوانتومی}
باوجود پتانسیل‌ها، محاسبات کوانتومی با چالش‌های بزرگی مواجه است. حفظ همدوسی کیوبیت‌ها به دلیل تعاملات محیطی که منجر به ناهمدوسی می‌شوند، دشوار است. علاوه بر این، پیاده‌سازی گیت‌های کوانتومی بادقت بالا نیاز به کنترل دقیق بر سامانه‌های کوانتومی دارد. رایانه‌های کوانتومی فعلی نیز محدود به تعداد کیوبیت‌ها و دقت عملیات کوانتومی هستند.

در نهایت، محاسبات کلاسیک و کوانتومی نمایانگر دو رویکرد اساسی به محاسبات هستند. درحالی‌که محاسبات کلاسیک برای مسائل قطعی و به‌خوبی درک شده مناسب است، محاسبات کوانتومی پتانسیل انقلابی در حل مسائل در حوزه‌هایی را دارد که رویکردهای کلاسیک ناکارآمد یا غیرعملی هستند. بااین‌حال، توسعهٔ رایانه‌های کوانتومی عملی، نیازمند غلبه بر چالش‌های فنی قابل‌توجهی از جمله تصحیح خطا و تحمل خطا است.

\section{شبیه‌سازهای مدار کوانتومی}
\label{sec:simulators}
در این قسمت، یک مرور جامع از مدل‌های مختلف شبیه‌سازی و شبیه‌سازهای محاسبات کوانتومی انجام شده است که نقاط قوت، ضعف‌ها و محدودیت‌های آن‌ها را به‌تفصیل بیان می‌کند. مقایسه بین مدل‌های مختلف، ملاحظات مربوط به‌دقت، مصرف منابع، مقیاس‌پذیری و انعطاف‌پذیری را برجسته می‌کند و بینش‌های ارزشمندی برای انتخاب ابزارهای شبیه‌سازی مناسب برای وظایف خاص محاسبات کوانتومی ارائه می‌دهد. تمامی قسمت‌های این بخش برگرفته از پژوهش \cite{young_simulating_2023} است مگر آن که به طور خاص به موارد دیگر ارجاع داده شده باشد.

\subsection{شبیه‌سازهای مبتنی بر Schrödinger}
این شبیه‌سازها به دلیل نمایش مستقیم حالت‌ها و تغییرات کوانتومی از دقت بالایی برخوردارند. به‌علاوه قادر به مدیریت مدارهای کوانتومی متوسط (حدود ۳۰ تا ۴۰ کیوبیت) هستند و قابلیت اجرا بر روی HPC\LTRfootnote{High-Performance Computer} را دارند. بااین‌همه، ضعف‌هایی در این دسته دیده می‌شود. نیاز به منابع محاسباتی قابل‌توجه، از جمله حافظه و قدرت پردازش، به دلیل رشد نمایی فضای حالت با تعداد کیوبیت‌ها و در نتیجه عدم مقیاس‌پذیری برای سامانه‌های بسیار بزرگ، نمونه‌ای از آن‌ها هستند.

\paragraph{شبیه‌ساز کوانتومی Intel :(IQS)}
شبیه‌ساز کوانتومی \lr{Intel} (IQS) از پلتفرم‌های محاسبات سریع (HPC) و ابری برای شبیه‌سازی حالت‌های کوانتومی توزیع شده با استفاده از گروه‌هایی از پردازنده‌های مرکزی (CPU) و پردازنده‌های گرافیکی (GPU) بهره می‌برد. IQS بردارهای دامنه‌های پیچیده را تقسیم کرده و هر قسمت را به فرایندهای مختلف تخصیص می‌دهد. این شبیه‌ساز قادر است سامانه‌هایی تا ۴۰ کیوبیت را شبیه‌سازی کند. تاکنون الگوریتم‌هایی مانند بهینه‌سازی تقریبی کوانتومی (QAOA) برای Max-Cut در گراف‌های ۳-منظم، تخمین فاز و تبدیل فوریه کوانتومی (QFT) با استفاده از آن شبیه‌سازی شده‌اند.
 
 \paragraph{:QuEST}
از بردارها برای نمایش حالت‌های خالص و از برهم‌نهی‌ها و ماتریس‌های چگالی برای حالت‌های کوانتومی مختلط استفاده می‌کند. این شبیه‌ساز از موازی‌سازی از طریق OpenMP و MPI پشتیبانی می‌کند که آن را برای پلتفرم‌های توزیع شده و چندرشته‌ای مناسب می‌سازد. QuEST می‌تواند مدارهای کوانتومی شبه‌تصادفی را تا ۳۸ کیوبیت شبیه‌سازی کند و یک‌زبان مبتنی بر C ارائه می‌دهد که روی پلتفرم‌های ترتیبی، چندرشته‌ای و موازی اجرا می‌شود.
 
 \paragraph{Aer :Qiskit}
توسط
\lr{IBM Quantum}
و
\lr{Qiskit}
ارائه شده است که برخلاف شبیه‌سازهای مبتنی بر نمونه‌برداری، تابع موج را به‌عنوان یک بردار حالت با اندازهٔ $2^n$ محاسبه و بازمی‌گرداند. این محاسبه به طور مداوم در حین اعمال گیت‌ها و دستورالعمل‌ها انجام می‌شود. این شبیه‌ساز از شبیه‌سازی‌های نویزی و ایده‌آل پشتیبانی کرده و مقیاس‌پذیری تا ۳۲ کیوبیت را پوشش می‌دهد.
 
 \paragraph{:Cirq}
این شبیه‌ساز که توسط Google توسعه‌یافته شده است، از ماتریس‌های پراکنده\LTRfootnote{Sparse Matrices} برای شبیه‌سازی حالت‌های خالص استفاده می‌کند. این شبیه‌ساز قادر است تا سخت‌افزار کوانتومی واقعی را شبیه‌سازی کند. مثلاً در حالتی که وضعیت اولیه به طور کامل صفر باشد و بردار حالت اولیه در دسترس نباشد. این شبیه‌ساز از اجراهای تصادفی نیز پشتیبانی می‌کند. درحالی‌که شبیه‌ساز وضعیت بردار را در پایان شبیه‌سازی ارائه می‌دهد، وضعیت اولیه می‌تواند با استفاده از یک بردار حالت کامل تعیین شود؛ اما این خود ضعف‌هایی مثل وابستگی به سخت‌افزار را در پی دارد. علاوه بر این، از شبیه‌سازی‌های خالص و نویزی پشتیبانی می‌کند، به‌طوری که شبیه‌سازی‌های نویزی از روش‌های تابع موج \lr{Monte Carlo} استفاده می‌کنند که در آن عملگرهای \lr{Kraus} به طور تصادفی نمونه‌برداری و به تابع موج اعمال می‌شوند.

\paragraph{:qsim}
یک شبیه‌ساز بردار حالت پیاده‌سازی شده با زبان
\lr{C++}
توسط
\lr{TensorFlow Quantum}
است که برای استفاده بر روی رایانه‌های شخصی طراحی شده و خروجی شبیه‌سازی را به‌صورت یک بردار حالت کامل ارائه می‌دهد. این شبیه‌ساز می‌تواند تا ۳۰ کیوبیت را با ۱۶ گیگابایت حافظه شبیه‌سازی کند، اگرچه نیاز به حافظه با هر کیوبیت اضافی دوبرابر می‌شود. شبیه‌ساز با انجام ضرب ماتریس - بردار برای هر گیت کار می‌کند و پیچیدگی زمان اجرای آن $O(g \cdot 2^n)$ است، درحالی‌که $g$ تعداد گیت‌های ۲-کیوبیتی است. بهینه‌سازی‌هایی مانند ادغام گیت‌ها، محاسبات بادقت یک رقم اعشار و موازی‌سازی با استفاده از OpenMP برای بهبود عملکرد به‌کارگرفته شده است.

\subsection{شبیه‌سازهای ترکیبی \lr{Schrödinger-Feynman}}
این طیف از شبیه‌سازها با بهره‌گیری از ترکیب نقاط قوت هر دو روش، امکان شبیه‌سازی کارآمد مدارهای کوانتومی بزرگ‌تر را فراهم کرده‌اند. همچنین، پشتیبانی از موازی‌سازی که می‌تواند کارایی محاسباتی را به طور قابل‌توجهی افزایش دهد، از دیگر نقاط قوت است. پیچیدگی بیش‌تر در پیاده‌سازی و بهینه‌سازی به دلیل طبیعت ترکیبی روش، نیاز به منابع محاسباتی قابل‌توجه به‌ویژه برای مدارهایی با عمق زیاد از نقاط ضعف این دسته هستند.
\paragraph{:DDSIM}
از روش ترکیبی \lr{Schrödinger-Feynman} برای شبیه‌سازی محاسبات کوانتومی با استفاده از نمودارهای تصمیم\LTRfootnote{Decision-Diagram} (QuIDD) استفاده می‌کند. این روش تغییرات کوانتومی را با تجزیه بازگشتی ماتریس‌ها به ماتریس‌های دو در دو ثبت می‌کند. تجزیهٔ Schmidt به گیت‌های دو کیوبیتی اعمال می‌شود که به‌صورت ضرب‌های تنسوری نمایش داده می‌شوند. این روش ترکیبی برای مدارهایی با عمق محدود مناسب است؛ زیرا تعداد اجراهای شبیه‌سازی با افزایش تعداد گیت‌های متقابل، به‌صورت نمایی، رشد می‌کند.

\paragraph{:Rollright}
این شبیه‌ساز توسط دانشگاه Michigan و Google توسعه‌یافته شده است. در این شبیه‌ساز روش‌های Schrödinger و Feynman ترکیب شده‌اند. این شبیه‌ساز کیوبیت‌ها را بر اساس استفاده از گیت‌ها گروه‌بندی کرده و گیت‌های کنترل‌شده مشترک در گروه‌ها را تجزیه می‌کند و قبل از ادغام نتایج در محاسبه کلی، محاسبات گیت‌های Schrödinger را روی هر گروه انجام می‌دهد.

\paragraph{:qsimh}
این شبیه‌ساز برگرفته و گسترش‌یافته‌ای از qsim است که شبیه‌سازی مسیر Feynman را با تقسیم شبکهٔ الگوریتم‌های کوانتومی به دو قسمت با استفاده از تجزیهٔ Schmidt پشتیبانی می‌کند. این شبیه‌ساز از موازی‌سازی در دستگاه‌های تک و چندگانه پشتیبانی می‌کند و ادعای آن بر این است که شبیه‌سازی‌های بیش از ۵۰ کیوبیت را مدیریت کند.

\subsection{شبیه‌سازهای مبتنی بر Heisenberg}
از کاربردهای درخشان این دسته از شبیه‌سازها، شبیه‌سازی کارآمد مدارهای پایدارکننده و معماری‌های خاص مقاوم به خطا است. بهینه‌سازی‌های پیشرفته مانند وارونگی جدول پایداری که سرعت شبیه‌سازی را افزایش می‌دهد، از دیگر برتری‌های این دسته به شمار می‌رود. از آن‌جایی که در صورت توجه خاص به یک بعد از بهینگی، دیگر ابعاد دچار کمبود خواهند شد، این قضیه در طراحی شبیه‌سازها نیز مستثنیٰ نیست. چون این دسته از شبیه‌سازها محدود به انواع خاصی از مدارها (مثلاً مدارهای پایدارکننده) هستند برای شبیه‌سازی عمومی مدارهای کوانتومی مناسب نمی‌باشند. دیگر نقطه‌ضعف این دسته، شبیه‌سازهای در حال توسعهٔ آن است که مستندات و پشتیبانی کاربر جامع و کاملی در دسترس ندارند.

\paragraph{:CHP}
یک شبیه‌ساز تخصصی برای مدارهای پایدارکنندهٔ کوانتومی است که برای مدیریت مدارهای بزرگ با هزاران کیوبیت بهینه شده است. این شبیه‌ساز از طراحی و رفع اشکال سامانه‌های تصحیح خطای کوانتومی و شبیه‌سازی حالت‌های بسیار درهم‌تنیده پشتیبانی می‌کند. CHP از یک‌زبان اسمبلی ساده برای مشخص‌کردن مدارها استفاده می‌کند و شامل گیت اندازه‌گیری تک‌کیوبیتی است. باوجود کارایی بالا، عملکرد CHP به دلیل افزایش منابع موردنیاز به‌صورت درجه دوم با افزایش تعداد کیوبیت‌ها محدود می‌شود.

\paragraph{:Stim}
توسعهٔ این شبیه‌ساز توسط Google انجام شده است که با اعمال بهبودهایی همچون بردارسازی، نمونه‌برداری از فریم مرجع و وارونگی جدول پایداری، کارایی شبیه‌ساز CHP را ارتقا می‌دهد. این بهبودها امکان پردازش کارآمدتر، به‌ویژه در مدیریت معماری‌های بزرگ و مقاوم به خطا در مدارهای کوانتومی را فراهم می‌کنند. Stim می‌تواند مدارهای پیچیده مانند مدارهای \lr{surface code} با ۲۰۰۰۰ کیوبیت را در عرض ۱۵ ثانیه تحلیل کند.

\subsection{مقایسه مدل‌های مختلف شبیه‌سازی}
\subsubsection{Schrödinger در مقابل ترکیبی \lr{Schrödinger-Feynman}}
شبیه‌سازهای مبتنی بر \lr{Schrödinger}، در توسعه به بلوغ نسبی بیش‌تری رسیده‌اند و درعین‌حال شبیه‌سازی دقیق‌تر حالت‌های کوانتومی را فراهم می‌کنند اما مصرف غیربهینهٔ منابع از مشکلات آن‌ها است درحالی‌که شبیه‌سازهای ترکیبی \lr{Schrödinger-Feynman}، همان‌طور که اشاره شد، با بهره‌گیری از موازی‌سازی و نقاط قوت دو روش ذیل، شبیه‌سازی‌های کارآمدتری را ارائه می‌دهند؛ ولی این برتری با پیچیدگی بیش‌تر در پیاده‌سازی و بهینه‌سازی همراه است.

\subsubsection{ترکیبی \lr{Schrödinger-Feynman} در مقابل Heisenberg}
همان‌طور که گفته شد، شبیه‌سازهای ترکیبی \lr{Schrödinger-Feynman}، شبیه‌سازهای کارآمدتر ولی با مشکل پیچیدگی در پیاده‌سازی هستند درحالی‌که شبیه‌سازهای مبتنی بر Heisenberg از دیگر شبیه‌سازها، کارآمدتر هستند؛ ولی فقط برای مدارهای خاص مثل مدارهای پایدارکننده قابل استفاده‌اند و برای شبیه‌سازی مدارهای عمومی کوانتومی مناسب نیستند.

\section{روش‌های محک}
در این بخش با بهره‌گیری از پژوهش \cite{acuaviva_benchmarking_2024} به بررسی روش‌های محک می‌پردازیم.

در حوزهٔ محاسبات کلاسیک، محک، برای بررسی جنبه‌های مختلف عملکرد سامانه، مانند سرعت، کارایی و استفاده از منابع، تکامل‌یافته است. بااین‌حال، ماهیت منحصربه‌فرد محاسبات کوانتومی چالش‌های جدیدی را به وجود می‌آورد که نیازمند تطبیق روش‌های سنتی با حوزهٔ کوانتوم است.

محک، شامل اجرای مجموعه‌ای از آزمایش‌های استاندارد روی سامانه‌های مختلف برای اندازه‌گیری و مقایسه عملکرد آن‌هاست. هدف این محک‌ها فراهم‌کردن یک روش قابل‌اعتماد و عینی برای ارزیابی قابلیت‌های سامانه‌های محاسباتی مختلف است که به کاربران و توسعه‌دهندگان امکان می‌دهد نقاط قوت و ضعف سامانه‌های مختلف را درک کنند.

به طور سنتی، محک در محاسبات کلاسیک بر روی معیارهایی مانند زمان اجرا، توان عملیاتی و کارایی متمرکز بوده است. این معیارها با استفاده از مجموعه‌ای از آزمایش‌های محک، از محک‌های ساختگی که وظایف محاسباتی خاصی را شبیه‌سازی می‌کنند تا محک‌های کاربردی واقعی که عملکرد سامانه‌ها را در شرایط استفاده معمولی منعکس می‌کنند، ارزیابی می‌شوند.

محاسبات کوانتومی تفاوت‌های اساسی با محاسبات کلاسیک دارد که نیازمند بازنگری روش‌های محک است. سامانه‌های کوانتومی با ویژگی‌هایی مانند برهم‌نهی، درهم‌تنیدگی و همدوسی کوانتومی مشخص می‌شوند که هیچ معادل مستقیمی در سامانه‌های کلاسیک ندارند. این ویژگی‌ها بر نحوهٔ پردازش اطلاعات و چگونگی اندازه‌گیری عملکرد، تأثیر بسزایی می‌گذارند.

یکی از چالش‌های اصلی در محک کوانتومی، نبود یک روش محاسباتی متحد در میان سامانه‌های کوانتومی مختلف است. برخلاف محاسبات کلاسیک که معماری‌ها نسبتاً استاندارد هستند، رایانه‌های کوانتومی می‌توانند بسته به فناوری زیربنایی (مانند یون‌های به‌دام‌افتاده، کیوبیت‌های ابررسانا، کیوبیت‌های فوتونی) به طور قابل‌توجهی متفاوت باشند. این تنوع، توسعهٔ یک محک واحد که بتواند به طور جامع در تمام سامانه‌های کوانتومی اعمال شود را دشوار می‌کند.

علاوه بر این، وضعیت نوپای فناوری محاسبات کوانتومی به این معناست که محک‌ها باید عواملی مانند نویز، نرخ خطا و تعداد محدود کیوبیت‌های موجود در سامانه‌های کنونی را در نظر بگیرند. این عوامل می‌توانند تأثیر زیادی بر عملکرد الگوریتم‌های کوانتومی داشته باشند و باید در طراحی محک‌ها به‌دقت در نظر گرفته شوند.

چندین روش برای محک سامانه‌های کوانتومی پیشنهاد شده است که هر یک بر جنبه‌های مختلف عملکردی تمرکز دارند. در زیر به برخی از رایج‌ترین روش‌های محک در محاسبات کوانتومی اشاره شده است:
\paragraph{محک تصادفی:}
محک تصادفی یک روش بسیار پرکاربرد برای اندازه‌گیری 
\lr{Fidelity}
گیت‌های کوانتومی است. به زبان ساده،
\lr{Fidelity}
، میزان شباهت نتیجه‌ٔ عملی را با نتیجهٔ دلخواه می‌سنجد‌. با اعمال یک دنباله از گیت‌های تصادفی کوانتومی و سپس معکوس‌های آن‌ها، نرخ خطای کلی یک سیستم کوانتومی را ارزیابی می‌کند. این تکنیک به ویژه در برابر خطاهای آماده‌سازی حالت و اندازه‌گیری مقاوم است که آن را برای ارزیابی عملکرد گیت‌های کوانتومی در محیط‌های پر نویز مفید می‌سازد.

\paragraph{\lr{Quantum Volume (QV)}:}
\lr{QV}
یک معیار جامع است که بزرگ‌ترین مدار کوانتومی که می‌توان با موفقیت بر روی یک رایانه کوانتومی اجرا کرد را اندازه‌گیری می‌کند. این معیار عواملی مانند تعداد کیوبیت‌ها، \lr{Fidelity} گیت‌ها و اتصال کیوبیت‌ها را در نظر می‌گیرد و یک عدد واحد را که نشان‌دهندهٔ عملکرد کلی سامانه است ارائه می‌دهد. بااین‌حال، این معیار محدودیت‌هایی دارد؛ زیرا به طور کامل عملکرد مدارهایی با طرح‌های غیرمربع (مدارهایی با عمق زیاد و عرض کم یا بالعکس) را منعکس نمی‌کند.

\paragraph{مدارهای آینه‌ای:}
روش مدار آینه‌ای شامل ایجاد مداری است که معکوس مدار کوانتومی داده شده باشد. با مقایسه نتایج مدارهای مستقیم و معکوس، این روش می‌تواند سازگاری و دقت محاسبات کوانتومی را ارزیابی کند. مدارهای آینه‌ای به‌ویژه برای محک مدارهایی که شامل گیت‌های \lr{Clifford} و $Z(\theta)$ هستند که در بسیاری از پردازنده‌های کوانتومی رایج‌اند، مفید هستند.

\paragraph{محک آنتروپی متقاطع:}
این روش برای ارزیابی برتری کوانتومی با مقایسه توزیع خروجی یک رایانهٔ کوانتومی با توزیع نظری مورد انتظار، استفاده می‌شود. با ارزیابی اینکه چقدر خروجی واقعی با توزیع مورد انتظار تطابق دارد، محک آنتروپی متقاطع معیاری از توانایی یک رایانهٔ کوانتومی برای انجام وظایفی که باور بر این است که برای سامانه‌های کلاسیک غیرقابل‌حل هستند، فراهم می‌کند.

همان‌طور که فناوری محاسبات کوانتومی به تکامل خود ادامه می‌دهد، توسعه روش‌های محک استاندارد برای پیشرفت این حوزه حیاتی خواهد بود. محک‌های آینده باید با معماری‌های جدید کوانتومی قابل‌تطبیق باشند و قادر به ارائهٔ مقایسه‌های معنادار در میان سامانه‌های مختلف باشند. علاوه بر این، همان‌طور که رایانه‌های کوانتومی قدرتمندتر می‌شوند، محک‌ها باید پیچیدگی روزافزون الگوریتم‌ها و سامانه‌های کوانتومی بزرگ‌تر را در نظر بگیرند.

ایجاد یک چارچوب محک استاندارد کوانتومی، مشابه با ارزیابی عملکرد استاندارد (SPEC) در محاسبات کلاسیک، می‌تواند پایه‌ای برای ارزیابی عملکرد سازگار و قابل‌اعتماد در محاسبات کوانتومی فراهم کند. چنین چارچوبی به هدایت توسعهٔ فناوری‌های کوانتومی کمک خواهد کرد و اطمینان حاصل خواهد کرد که ادعاهای عملکردی بر اساس محک‌های دقیق و قابل تکرار، استوار هستند.

\section{چگونگی تولد رایانش کوانتومی و اهداف آن}
ظهور رایانش کوانتومی به اوایل دهه ۱۹۸۰ بازمی‌گردد، زمانی که فیزیک‌دان، \lr{Richard Feynman}، ایدهٔ استفاده از مکانیک کوانتومی برای انجام محاسبات را مطرح کرد. Feynman مشاهده کرد که رایانه‌های کلاسیک در شبیه‌سازی سامانه‌های کوانتومی با چالش‌های قابل‌توجهی مواجه هستند، زیرا پیچیدگی مرتبط با حالت‌های کوانتومی به‌صورت نمایی افزایش می‌یابد. این بینش منجر به پایه‌گذاری مفهومی تحت عنوان «رایانش کوانتومی» شد که هدف آن استفاده از پدیده‌های مکانیکی کوانتومی برای پردازش اطلاعات با کارایی بیش‌تری نسبت به رایانه‌های کلاسیک است. رایانش کوانتومی، بهره‌برداری از اصول برهم‌نهی، درهم‌تنیدگی و تداخل کوانتومی برای حل مسائل پیچیده‌ای است که برای رایانه‌های کلاسیک غیرقابل‌حل هستند. رایانه‌های کوانتومی برای انجام وظایفی مانند فاکتورگیری اعداد بزرگ، جستجو در پایگاه‌های مه‌داده‌ها و شبیه‌سازی فرایندهای فیزیکی کوانتومی طراحی شده‌اند که با سرعت بسیار بیش‌تری نسبت به همتایان کلاسیک خود این فعالیت‌ها را انجام می‌دهند. این پتانسیل برای افزایش توان محاسباتی، باعث تحقیقات و توسعه مداوم در این زمینه شده است با این امید که پیشرفت‌های چشم‌گیری در حوزه‌های علمی و فناوری مختلف به دست آید \cite{nielsen_quantum_2010}.
\section{نقش شبیه‌سازهای مدار کوانتومی در پیشبرد رایانش کوانتومی}
شبیه‌سازهای مدار کوانتومی نقش مهمی در پیشبرد رایانش کوانتومی دارند؛ زیرا بستری را برای طراحی، آزمایش و بهینه‌سازی الگوریتم‌های کوانتومی قبل از پیاده‌سازی آن‌ها روی سخت‌افزار واقعی کوانتومی فراهم می‌کنند. این شبیه‌سازها رفتار مدارهای کوانتومی را مدل‌سازی می‌کنند و به پژوهشگران این امکان را می‌دهند تا ویژگی‌ها و عملکرد الگوریتم‌های کوانتومی را تحت شرایط کنترل‌شده بررسی کنند. این قابلیت برای درک مزایای محاسباتی مکانیک کوانتومی و شناسایی مشکلات احتمالی در طراحی الگوریتم بسیار ضروری است \cite{nielsen_quantum_2010}.

یکی از وظایف شبیه‌سازهای مدار کوانتومی این است که شبیه‌سازی سامانه‌های کوانتومی را که برای رایانه‌های کلاسیک بسیار پیچیده هستند، امکان‌پذیر کنند. با استفاده از شبیه‌سازهای مدار کوانتومی، پژوهشگران می‌توانند درک بهتری از دینامیک الگوریتم‌های کوانتومی پیدا کنند، راهبُردهای محاسباتی جدیدی را کشف کنند و رویکردهای خود را برای بهره‌برداری کامل از پتانسیل رایانش کوانتومی بهینه‌سازی کنند. این فرایند تکراری شبیه‌سازی و بهینه‌سازی برای توسعهٔ عملی فناوری‌های رایانش کوانتومی ضروری است و راه را برای سامانه‌های کوانتومی مقاوم‌تر و مقیاس‌پذیرتر در آینده، هموار می‌کند \cite{nielsen_quantum_2010}.
\section{پرسش‌های پژوهش}
توضیح این پرسش‌ها برای واضح کردن رویهٔ پژوهش بوده است. تمامی پرسش‌های گفته‌شده برای محک کلی رایانه‌های کوانتومی در لایه‌های مختلف آن یعنی نرم‌افزار، میان‌افزار و سخت‌افزارها بوده است. از آن‌جایی که در پژوهش ما تمرکز بر محک شبیه‌سازهای مدار کوانتومی است، معیارها همان معیارهایی است که در فصل اول، مقدمه، بیان شده است چرا که بعضی معیارها زمانی باید مورداستفاده قرار بگیرند که تمامی قسمت‌های رایانه‌های کوانتومی اعم از نرم‌افزار، میان‌افزار و سخت‌افزار در اجرای این محک‌ها دخیل باشند.

\subsection*{معیارهای عملکرد کلیدی برای محک منصفانه‌ی شبیه‌سازهای مدار کوانتومی چیست؟}

\subsubsection{زمان شبیه‌سازی}
این زمان، زمان کلی موردنیاز برای شبیه‌سازی یک مدار کوانتومی است. این معیار بسیار مهم است زیرا بازتابی از کارایی و سرعت شبیه‌ساز است. عواملی که بر زمان شبیه‌سازی تأثیر می‌گذارند شامل پیچیدگی مدار کوانتومی، تعداد کیوبیت‌ها و ماهیت الگوریتمی است که شبیه‌سازی می‌شود\cite{lubinski_application-oriented_2023, jamadagni_benchmarking_2024}.

\subsubsection{مصرف حافظه}
اندازه‌گیری مقدار حافظه‌ای که برای انجام شبیه‌سازی موردنیاز است از دیگر معیارهای مهم به شمار می‌رود. این معیار به‌ویژه برای شبیه‌سازی‌های بزرگ‌مقیاس که محدودیت‌های حافظه می‌تواند به یک عامل محدودکننده تبدیل شود، اهمیت دارد. به دلیل رشد نمایی فضای حالت کوانتومی با افزایش تعداد کیوبیت‌ها، شبیه‌سازهای کوانتومی، اغلب نیاز به مدیریت مقادیر زیادی از داده‌ها دارند \cite{lubinski_application-oriented_2023}.

\subsubsection{قابلیت مقیاس‌پذیری}
توانایی شبیه‌ساز برای مدیریت افزایش تعداد کیوبیت‌ها و عمق مدار\LTRfootnote{circuit depth}، قابلیت مقیاس‌پذیری نامیده می‌شود. عمق مدار، همان تعداد لایه‌هایی است که میزان پیچیدگی مدارهای کوانتومی را می‌سنجد. مقیاس‌پذیری برای کاربردهای عملی شبیه‌سازی کوانتومی، حیاتی است؛ زیرا تعیین می‌کند که شبیه‌ساز چگونه می‌تواند مشکلات واقعی با اندازه و پیچیدگی قابل‌توجه را مدیریت کند \cite{jamadagni_benchmarking_2024, lubinski_application-oriented_2023}.
\subsubsection{دقت}
میزان دقتی که شبیه‌ساز می‌تواند رفتار یک سامانهٔ کوانتومی را تکرار کند نیز باید مورد محک قرار بگیرد. این، شامل چگونگی برخورد شبیه‌ساز با نویز کوانتومی، کاهش ناهمدوسی و سایر اثرات کوانتومی است که بر صحت نتایج شبیه‌سازی تأثیر بسزایی می‌گذارند \cite{jamadagni_benchmarking_2024, lubinski_application-oriented_2023}.
\subsubsection{انعطاف‌پذیری}
از توانایی شبیه‌ساز برای پشتیبانی از الگوریتم‌های مختلف کوانتومی و انواع مختلف مدارهای کوانتومی به انعطاف‌پذیری یاد می‌شود. انعطاف‌پذیری شامل پشتیبانی از زبان‌های برنامه‌نویسی مختلف و ادغام با چارچوب‌های مختلف رایانش کوانتومی است \cite{jamadagni_benchmarking_2024, lubinski_application-oriented_2023, young_simulating_2023}.
\subsubsection{پیچیدگی پیاده‌سازی الگوریتم‌های کوانتومی}
پیاده‌سازی الگوریتم‌ها در شبیه‌سازهای مختلف، متفاوت است، به‌گونه‌ای که هر کدام باتوجه‌به فنّاوری مورداستفاده مثل زبان برنامه‌نویسی، قابلیت اجرا بر روی سخت‌افزارهای خاص، دارای پیچیدگی‌های منحصربه‌فرد هستند. این معیار، ترکیبی از زمان یادگیری نحوهٔ استفاده از شبیه‌ساز و زمان پیاده‌سازی یک الگوریتم در آن است که باتوجه‌به این که به توانایی افراد وابسته است، یک معیار کیفی است؛ اما به دلیل تأثیر زیاد آن در روند پیاده‌سازی، لایق بررسی است.

\subsection*{عملکرد شبیه‌سازهای مختلف بر روی الگوریتم‌های مختلف کوانتومی چگونه است؟}
شبیه‌سازهای مختلف مدار کوانتومی، عملکرد متفاوتی بر روی الگوریتم‌های کوانتومی مختلف دارند. قسمت‌های زیر ویژگی‌های عملکرد‌های مشاهده شده را خلاصه می‌کنند.
\subsubsection{شبیه‌سازهای مبتنی بر Schrödinger}
این شبیه‌سازها که بر پایهٔ نمایش مستقیم بردار حالت، استوار هستند. به دلیل پیاده‌سازی ساده و کاربرد عمومی، به طور گسترده‌ای استفاده می‌شوند. بااین‌حال، آن‌ها اغلب در مقیاس‌بندی به بیش از یک تعداد خاص از کیوبیت‌ها به دلیل نیازهای حافظه‌ای نمایی با چالش‌هایی مواجه می‌شوند \cite{young_simulating_2023}.

\subsubsection{شبیه‌سازهای مبتنی بر شبکهٔ تنسوری}
این شبیه‌سازها در مدارهای کوانتومی با محدودیت درهم‌تنیدگی، خوب عمل می‌کنند. با نمایش حالت‌های کوانتومی به‌عنوان شبکه‌های تنسوری، می‌توانند برخی از دسته‌های مدارهای کوانتومی را که با روش‌های مبتنی بر Schrödinger غیرقابل‌حل هستند، به طور کارآمد شبیه‌سازی کنند. بااین‌حال، ممکن است با مدارهایی که شامل درجات بالایی از درهم‌تنیدگی هستند، دچار مشکل شوند \cite{young_simulating_2023}.
\subsubsection{روش‌های ترکیبی}
این روش‌ها، ترکیبی از فن‌های شبیه‌سازی مختلف را برای بهره‌برداری از نقاط قوت هر یک ترکیب می‌کنند. به‌عنوان‌مثال، ادغام شبکه‌های تنسوری با روش‌های مبتنی بر Schrödinger می‌تواند تعادلی بین استفاده از حافظه و کارایی زمانی ایجاد کند که آن‌ها را برای طیف وسیع‌تری از مدارهای کوانتومی مناسب می‌سازد \cite{young_simulating_2023}.

\subsubsection{شبیه‌سازها با کاربرد خاص}
شبیه‌سازهایی که برای انواع خاصی از مدارها یا الگوریتم‌های کوانتومی بهینه‌سازی شده‌اند، مانند مدارهای پایدارکننده\LTRfootnote{Stabilizer Circuits} یا الگوریتم‌های کوانتومی متغیر\LTRfootnote{Variational Quantum Algorithms (VQA)}، در دامنه‌های مربوط به خود، عملکرد بهتری نسبت به شبیه‌سازهای عمومی دارند. این شبیه‌سازهای خاص می‌توانند به طور قابل‌توجهی زمان شبیه‌سازی و نیازهای منابع را برای کاربردهای هدف خود، کاهش دهند \cite{young_simulating_2023}.

\subsubsection{شبیه‌سازها با سخت‌افزار خاص}
شبیه‌سازهایی که برای بهره‌برداری از ویژگی‌های خاص سخت‌افزاری، مانند پردازنده‌های گرافیکی، طراحی شده‌اند، می‌توانند به بهبودهای قابل‌توجهی در عملکرد دست یابند. این شبیه‌سازها از قابلیت‌های پردازش موازی برای مدیریت سامانه‌های کوانتومی بزرگ‌تر با کارایی بیشتر نسبت به شبیه‌سازهای مبتنی بر CPU سنتی استفاده می‌کنند \cite{young_simulating_2023, xu_herculean_2023}.


\subsection*{نقاط قوت و ضعف شبیه‌سازهای فعلی در چه قسمت‌هایی است؟}
\subsubsection{نقاط قوت}
\paragraph{دقت بالا:}
بسیاری از شبیه‌سازهای فعلی، شبیه‌سازی‌هایی بادقت بالا ارائه می‌دهند که برای آزمایش و اعتبارسنجی الگوریتم‌های کوانتومی ضروری است. آن‌ها می‌توانند رفتار سامانه‌های کوانتومی را به طور دقیقی تکرار کنند که برای تحقیقات و توسعه در رایانش کوانتومی بسیار مهم است \cite{young_simulating_2023}.

\paragraph{عمومیت:}
شبیه‌سازهای مدرن از طیف وسیعی از الگوریتم‌ها و کاربردهای کوانتومی پشتیبانی می‌کنند، از گیت‌های کوانتومی پایه تا کدهای پیچیده تصحیح خطای کوانتومی. این عمومیت، آن‌ها را به ابزارهای ارزشمندی برای حوزه‌های مختلف تحقیقات رایانش کوانتومی تبدیل کرده است \cite{xu_herculean_2023}.

\paragraph{ویژگی‌های پیشرفته:}
برخی از شبیه‌سازها ویژگی‌های پیشرفته‌ای مانند مدل‌سازی نویز، شبیه‌سازی تصحیح خطا و پشتیبانی از الگوریتم‌های کوانتومی متغیر را ارائه می‌دهند که برای شبیه‌سازی‌های واقع‌گرایانه و توسعه رایانش کوانتومی مقاوم به خطا، ضروری هستند \cite{jamadagni_benchmarking_2024}.

\subsubsection{نقاط ضعف}
\paragraph{مشکلات مقیاس‌پذیری:}
بسیاری از شبیه‌سازها با مقیاس‌بندی به تعداد بیش‌تری از کیوبیت‌ها به دلیل افزایش نمایی در نیازهای حافظه و محاسبات، با چالش‌هایی مواجه هستند. این محدودیت‌ها استفاده آن‌ها را برای سامانه‌های کوانتومی بزرگ‌تر و مسائل واقعی محدود می‌کند \cite{xu_herculean_2023}.

\paragraph{مصرف منابع زیاد:}
استفاده بالا از حافظه و زمان طولانی شبیه‌سازی چالش‌های رایجی هستند. شبیه‌سازی مدارهای بزرگ کوانتومی اغلب به منابع محاسباتی قابل‌توجهی نیاز دارد که برای بسیاری از کاربران بدون دسترسی به امکانات محاسباتی قوی، عملی نیست \cite{young_simulating_2023}.

\paragraph{محدودیت‌های تخصصی:}
درحالی‌که شبیه‌سازهای خاص در حوزه‌های خود عالی هستند، اغلب فاقد انعطاف‌پذیری برای مدیریت انواع مختلف مدارهای کوانتومی هستند. این نیاز به استفاده از چندین شبیه‌ساز برای پوشش جنبه‌های مختلف رایانش کوانتومی را ایجاد می‌کند که می‌تواند فرایند شبیه‌سازی را بسیار زمان‌بر و پیچیده کند \cite{jamadagni_benchmarking_2024}.

\paragraph{پیچیدگی:}
پیچیدگی راه‌اندازی و اجرای شبیه‌سازی‌ها، می‌تواند مانعی برای ورود کاربران جدید باشد. دانش دقیقی از اصول رایانش کوانتومی و ساختار خاص شبیه‌ساز اغلب برای دستیابی به عملکرد بهینه، موردنیاز است \cite{jamadagni_benchmarking_2024}.
